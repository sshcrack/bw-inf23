{
  "hash": "064a3515896a8c64ecf5958a50ebd2ef",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"1. Aufgabe: Störung\"\nformat:\n  html:\n    css: \"../../styles.css\"\n    toc: true\n    toc-title: \"Inhalt\"\n---\n\n::: {.callout-note appearance=\"simple\"}\n## Die Aufgabe\nAlice und Bob tauschen in ihrem persönlichen Chat\ngerne Sätze aus, die Zitate aus ihrem Lieblingsbuch sind. Leider hat Trudi einen Weg gefunden,\nLücken in die Sätze zu reißen und ganze Wörter\nverschwinden zu lassen. So empfing Bob vor\nKurzem diesen Lückensatz von Alice, den er nicht\nverstehen konnte:\n\n`das ... mir ... ... ... vor`\n\nEr musste lange im Buch blättern, bis er diese\npassende Stelle darin fand:\n\n`das kommt mir gar nicht richtig vor`\n\nAber er ist unsicher, denn schließlich könnte es ja\nnoch andere passende Stellen geben.\nAlice und Bob überlegen, wie sie das Problem\nlösen können. Den Text des Lieblingsbuches gibt\nes auch digital. Da könnte es doch möglich sein,\nsich die Suche nach passenden Stellen von einem\nComputerprogramm abnehmen zu lassen.\n:::\n\n## Unser Ansatz: Textmustersuche mit Regulären Ausdrücken\n\nDas Problem, das Alice und Bob haben, ist ein klassisches Mustererkennungsproblem: Wie findet man einen Teilsatz, bei dem nur einige Wörter bekannt sind, während andere Wörter fehlen?\n\nFür die Lösung bietet sich die Verwendung von **regulären Ausdrücken** (Regular Expressions, kurz RegEx) an. Mit RegEx können wir flexible Muster definieren, die genau unserem Problem entsprechen:\n\n1. Bekannte Wörter bleiben unverändert im Suchmuster\n2. Lücken (fehlende Wörter) werden durch einen Platzhalter ersetzt, der \"irgendein Wort\" repräsentiert\n3. Die Reihenfolge der Wörter bleibt erhalten\n\n### Die Hauptschritte des Algorithmus:\n\n1. **Eingabe lesen**: Wir lesen die \"gestörten\" Sätze aus den Dateien\n2. **Muster erstellen**: Wir erstellen ein RegEx-Muster, das bekannte Wörter und Lücken enthält\n3. **Suche durchführen**: Wir durchsuchen den Text nach passenden Stellen\n4. **Ergebnisse anzeigen**: Wir zeigen die gefundenen kompletten Sätze an\n\n## Dateien\n\n::: {#list-files .cell execution_count=1}\n- [Alice_im_Wunderland.txt](files/Alice_im_Wunderland.txt)\n- [stoerung0.txt](files/stoerung0.txt)\n- [stoerung1.txt](files/stoerung1.txt)\n- [stoerung2.txt](files/stoerung2.txt)\n- [stoerung3.txt](files/stoerung3.txt)\n- [stoerung4.txt](files/stoerung4.txt)\n- [stoerung5.txt](files/stoerung5.txt)\n- [text-analysis.svg](files/text-analysis.svg)\n:::\n\n\n::: {.callout-tip}\nDie Dateien `stoerung0.txt` bis `stoerung5.txt` enthalten die lückenhaften Sätze, wobei `_` für ein fehlendes Wort steht. Die Datei `Alice_im_Wunderland.txt` enthält den vollständigen Text des Buches.\n:::\n\n## Implementierung der Lösung\n\nUnsere Implementierung verwendet die `re`-Bibliothek in Python, um reguläre Ausdrücke zu verarbeiten:\n\n::: {#code-explanation .cell execution_count=2}\n``` {.python .cell-code code-fold=\"false\"}\n# Regex-Muster für ein beliebiges Wort\nword_pattern = \"([a-z])\\\\w+\"\n\n# Für jede Lücke (_) verwenden wir das Wort-Muster\n# Für bekannte Wörter verwenden wir den exakten Text\n```\n:::\n\n\n## Lösung\n\n::: {#exercise-fig .cell execution_count=3}\n``` {.python .cell-code code-fold=\"true\"}\nimport re\n\nquestions: list[str] = []\nfor i in range(0, 6):\n    file_name = \"files/stoerung\" + str(i) + \".txt\"\n    with open(file_name) as f:\n        questions.append(f.read())\n\nbase_text = \"\"\nwith open(\"files/Alice_im_Wunderland.txt\") as b:\n    base_text = b.read().lower()\n\nfor i, question in enumerate(questions):\n    parts = question.split(\" \")\n    regex_parts = []\n\n    for part in parts:\n        if part == \"_\":\n            regex_parts.append(\"([a-z])\\\\w+\")\n        else:\n            regex_parts.append(part)\n\n    regex = \" \".join(regex_parts)\n\n    matches = re.search(regex, base_text, re.IGNORECASE)\n    if matches is None:\n        print(\"No match found for:\", regex)\n        continue\n\n    m = matches.group(0).split(\" \")\n    print(f\"Lösung zu Störung {i}\\n\")\n    print(f\"\\n\\n**Lückensatz:** `{question}`\\n\")\n    print(f\"**Vollständiger Satz:**\")\n\n    result = []\n    for j, part in enumerate(parts):\n        if part != \"_\":\n            result.append(part)\n        else:\n            result.append(f\"**{m[j]}**\")\n\n    print(f\"`{' '.join(result)}`\")\n    print(\"\\n\\n<br><br>\")\n```\nLösung zu Störung 0\n\n\n\n**Lückensatz:** `das _ mir _ _ _ vor`\n\n**Vollständiger Satz:**\n`das **kommt** mir **gar** **nicht** **richtig** vor`\n\n\n<br><br>\nLösung zu Störung 1\n\n\n\n**Lückensatz:** `ich muß _ clara _`\n\n**Vollständiger Satz:**\n`ich muß **in** clara **verwandelt**`\n\n\n<br><br>\nLösung zu Störung 2\n\n\n\n**Lückensatz:** `fressen _ gern _`\n\n**Vollständiger Satz:**\n`fressen **katzen** gern **spatzen**`\n\n\n<br><br>\nLösung zu Störung 3\n\n\n\n**Lückensatz:** `das _ fing _`\n\n**Vollständiger Satz:**\n`das **spiel** fing **an**`\n\n\n<br><br>\nLösung zu Störung 4\n\n\n\n**Lückensatz:** `ein _ _ tag`\n\n**Vollständiger Satz:**\n`ein **sehr** **schöner** tag`\n\n\n<br><br>\nLösung zu Störung 5\n\n\n\n**Lückensatz:** `wollen _ so _ sein`\n\n**Vollständiger Satz:**\n`wollen **sie** so **gut** sein`\n\n\n<br><br>\n:::\n\n\n## Diskussion des Ansatzes\n\nDiese Methode hat einige interessante Eigenschaften:\n\n1. **Flexibilität**: Der Ansatz funktioniert für beliebig viele Lücken in einem Satz\n2. **Effizienz**: Reguläre Ausdrücke sind für Textsuche optimiert und arbeiten sehr schnell\n3. **Grenzen**: Es kann zu falschen Treffern kommen, wenn die vorhandenen Wörter nicht eindeutig genug sind\n\nFür eine erweiterte Lösung könnte man:\n\n- Kontextinformationen berücksichtigen (z.B. Kapitel oder Abschnitte)\n- Mehrere mögliche Treffer anzeigen und bewerten\n- Sprachmodelle einsetzen, um die wahrscheinlichste Vervollständigung zu finden\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}